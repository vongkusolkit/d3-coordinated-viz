logitmodel1 <- glm(default ~ income, family=binomial(link='logit'),data=trainData)
pred_prob1 <- predict(logitmodel1,newdata=testData,type="response")
pred.log1 <- ifelse(round(pred_prob1)==1,"Yes","No")
pred.log1= as.factor(pred.log1)
pred1 <- ifelse(round(pred_prob1)==1,"Yes","No") #ed1, testData[,"default"]) #create the prediction result table
accuracy_table_log1 <- table(pred1, testData[,"default"]) #create the prediction result table
accuracy.log1 <- sum(diag(accuracy_table_log1))/sum(accuracy_table_log1)
accuracy_list_log.1[i] <- accuracy.log1
####balance
logitmodel2 <- glm(default ~ balance, family=binomial(link='logit'),data=trainData)
pred_prob2 <- predict(logitmodel2,newdata=testData,type="response") #predic the probablity of default behavior with different balance values
pred.log2 <- ifelse(round(pred_prob2)==1,"Yes","No")
pred.log2= as.factor(pred.log2)
pred2 <- ifelse(round(pred_prob2)==1,"Yes","No")
accuracy_table_log2 <- table(pred2, testData[,"default"]) #create the prediction result table
accuracy.log2 <- sum(diag(accuracy_table_log2))/sum(accuracy_table_log2)
accuracy_list_log.2[i] <- accuracy.log2
####student
logitmodel3 <- glm(default ~ student, family=binomial(link='logit'),data=trainData)
pred_prob3 <- predict(logitmodel3,newdata=testData,type="response")
pred.log3 <- ifelse(round(pred_prob3)==1,"Yes","No")
pred.log3= as.factor(pred.log3)
pred3 <- ifelse(round(pred_prob3)==1,"Yes","No")
accuracy_table_log3 <- table(pred3, testData[,"default"]) #create the prediction result table
accuracy.log3 <- sum(diag(accuracy_table_log3))/sum(accuracy_table_log3)
accuracy_list_log.3[i] <- accuracy.log3
####income+balance
logitmodel4 <- glm(default ~ income+balance, family=binomial(link='logit'),data=trainData)
pred_prob4 <- predict(logitmodel4,newdata=testData,type="response")
pred.log4 <- ifelse(round(pred_prob4)==1,"Yes","No")
pred.log4 = as.factor(pred.log4)
pred4 <- ifelse(round(pred_prob4)==1,"Yes","No")
accuracy_table_log4 <- table(pred4, testData[,"default"]) #create the prediction result table
accuracy.log4 <- sum(diag(accuracy_table_log4))/sum(accuracy_table_log4)
accuracy_list_log.4[i] <- accuracy.log4
####student
logitmodel5 <- glm(default ~ income+balance+student, family=binomial(link='logit'),data=trainData)
pred_prob5 <- predict(logitmodel5,newdata=testData,type="response")
pred.log5 <- ifelse(round(pred_prob5)==1,"Yes","No")
pred.log5 = as.factor(pred.log5)
pred5 <- ifelse(round(pred_prob5)==1,"Yes","No")
accuracy_table_log5 <- table(pred5, testData[,"default"]) #create the prediction result table
accuracy.log5 <- sum(diag(accuracy_table_log5))/sum(accuracy_table_log5)
accuracy_list_log.5[i] <- accuracy.log5
####balance + student
logitmodel6 <- glm(default ~ balance+student, family=binomial(link='logit'),data=trainData)
pred_prob6 <- predict(logitmodel6,newdata=testData,type="response")
pred.log6 <- ifelse(round(pred_prob6)==1,"Yes","No")
pred.log6 = as.factor(pred.log6)
pred6 <- ifelse(round(pred_prob6)==1,"Yes","No")
accuracy_table_log6 <- table(pred6, testData[,"default"]) #create the prediction result table
accuracy.log6 <- sum(diag(accuracy_table_log6))/sum(accuracy_table_log6)
accuracy_list_log.6[i] <- accuracy.log6
####income + student
logitmodel7 <- glm(default ~ income+student, family=binomial(link='logit'),data=trainData)
pred_prob7 <- predict(logitmodel7,newdata=testData,type="response")
pred.log7 <- ifelse(round(pred_prob7)==1,"Yes","No")
pred.log7 = as.factor(pred.log7)
pred7 <- ifelse(round(pred_prob7)==1,"Yes","No")
accuracy_table_log7 <- table(pred7, testData[,"default"]) #create the prediction result table
accuracy.log7 <- sum(diag(accuracy_table_log7))/sum(accuracy_table_log7)
accuracy_list_log.7[i] <- accuracy.log7
#save data for #2
if (i == 2) {
pred.nb.2 = pred.nb.4
pred.log.2 = pred.log4
test2 = testData
}
}
# Naive Bayesâ€™ Classifier
library(e1071)
if(!require("caret")) install.packages("caret")
library("caret")
yourData<-Default[sample(nrow(Default)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(yourData)),breaks=10,labels=FALSE)
#Perform 10-fold cross validation
accuracy_list_log.1 <- NULL
accuracy_list_log.2 <- NULL
accuracy_list_log.3 <- NULL
accuracy_list_log.4 <- NULL
accuracy_list_log.5 <- NULL
accuracy_list_log.6 <- NULL
accuracy_list_log.7 <- NULL
accuracy_list_nb.1 <- NULL
accuracy_list_nb.2 <- NULL
accuracy_list_nb.3 <- NULL
accuracy_list_nb.4 <- NULL
accuracy_list_nb.5 <- NULL
accuracy_list_nb.6 <- NULL
accuracy_list_nb.7 <- NULL
for(i in 1:10){
#Segement data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testData <- yourData[testIndexes, ]
trainData <- yourData[-testIndexes, ]
#create model/prediction/accuracy using income
naiveBayesmodel1 <- naiveBayes(default ~ income, data = trainData) # consider two predictors
pred.nb.1 <- predict(naiveBayesmodel1,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_1 <- table(pred.nb.1, testData[,"default"]) #create the prediction result table
accuracy.nb.1 <- sum(diag(accuracy_table_nb_1))/sum(accuracy_table_nb_1)
accuracy_list_nb.1[i] <- accuracy.nb.1
#create model/prediction/accuracy using balance
naiveBayesmodel2 <- naiveBayes(default ~ balance, data = trainData) # consider two predictors
pred.nb.2 <- predict(naiveBayesmodel2,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_2 <- table(pred.nb.2, testData[,"default"]) #create the prediction result table
accuracy.nb.2 <- sum(diag(accuracy_table_nb_2))/sum(accuracy_table_nb_2)
accuracy_list_nb.2[i] <- accuracy.nb.2
#create model/prediction/accuracy using student
naiveBayesmodel3 <- naiveBayes(default ~ student, data = trainData) # consider two predictors
pred.nb.3 <- predict(naiveBayesmodel3,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_3 <- table(pred.nb.3, testData[,"default"]) #create the prediction result table
accuracy.nb.3 <- sum(diag(accuracy_table_nb_3))/sum(accuracy_table_nb_3)
accuracy_list_nb.3[i] <- accuracy.nb.3
#create model/prediction/accuracy using income+balance
naiveBayesmodel4 <- naiveBayes(default ~ income+balance, data = trainData) # consider two predictors
pred.nb.4 <- predict(naiveBayesmodel4,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_4 <- table(pred.nb.4, testData[,"default"]) #create the prediction result table
accuracy.nb.4 <- sum(diag(accuracy_table_nb_4))/sum(accuracy_table_nb_4)
accuracy_list_nb.4[i] <- accuracy.nb.4
#create model/prediction/accuracy using income+balance+student
naiveBayesmodel5 <- naiveBayes(default ~ income+balance+student, data = trainData) # consider two predictors
pred.nb.5 <- predict(naiveBayesmodel5,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_5 <- table(pred.nb.5, testData[,"default"]) #create the prediction result table
accuracy.nb.5 <- sum(diag(accuracy_table_nb_5))/sum(accuracy_table_nb_5)
accuracy_list_nb.5[i] <- accuracy.nb.5
#create model/prediction/accuracy using balance+student
naiveBayesmodel6 <- naiveBayes(default ~ balance+student, data = trainData) # consider two predictors
pred.nb.6 <- predict(naiveBayesmodel6,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_6 <- table(pred.nb.6, testData[,"default"]) #create the prediction result table
accuracy.nb.6 <- sum(diag(accuracy_table_nb_6))/sum(accuracy_table_nb_6)
accuracy_list_nb.6[i] <- accuracy.nb.6
#create model/prediction/accuracy using income+student
naiveBayesmodel7 <- naiveBayes(default ~ income+student, data = trainData) # consider two predictors
pred.nb.7 <- predict(naiveBayesmodel7,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_7 <- table(pred.nb.7, testData[,"default"]) #create the prediction result table
accuracy.nb.7 <- sum(diag(accuracy_table_nb_7))/sum(accuracy_table_nb_7)
accuracy_list_nb.5[i] <- accuracy.nb.7
# cat("logistic regression model for ith fold: ", i, "\n")
# Run the logistic regression model  for categorical label prediction
logitmodel1 <- glm(default ~ income, family=binomial(link='logit'),data=trainData)
pred_prob1 <- predict(logitmodel1,newdata=testData,type="response")
pred.log1 <- ifelse(round(pred_prob1)==1,"Yes","No")
pred.log1= as.factor(pred.log1)
pred1 <- ifelse(round(pred_prob1)==1,"Yes","No") #ed1, testData[,"default"]) #create the prediction result table
accuracy_table_log1 <- table(pred1, testData[,"default"]) #create the prediction result table
accuracy.log1 <- sum(diag(accuracy_table_log1))/sum(accuracy_table_log1)
accuracy_list_log.1[i] <- accuracy.log1
####balance
logitmodel2 <- glm(default ~ balance, family=binomial(link='logit'),data=trainData)
pred_prob2 <- predict(logitmodel2,newdata=testData,type="response") #predic the probablity of default behavior with different balance values
pred.log2 <- ifelse(round(pred_prob2)==1,"Yes","No")
pred.log2= as.factor(pred.log2)
pred2 <- ifelse(round(pred_prob2)==1,"Yes","No")
accuracy_table_log2 <- table(pred2, testData[,"default"]) #create the prediction result table
accuracy.log2 <- sum(diag(accuracy_table_log2))/sum(accuracy_table_log2)
accuracy_list_log.2[i] <- accuracy.log2
####student
logitmodel3 <- glm(default ~ student, family=binomial(link='logit'),data=trainData)
pred_prob3 <- predict(logitmodel3,newdata=testData,type="response")
pred.log3 <- ifelse(round(pred_prob3)==1,"Yes","No")
pred.log3= as.factor(pred.log3)
pred3 <- ifelse(round(pred_prob3)==1,"Yes","No")
accuracy_table_log3 <- table(pred3, testData[,"default"]) #create the prediction result table
accuracy.log3 <- sum(diag(accuracy_table_log3))/sum(accuracy_table_log3)
accuracy_list_log.3[i] <- accuracy.log3
####income+balance
logitmodel4 <- glm(default ~ income+balance, family=binomial(link='logit'),data=trainData)
pred_prob4 <- predict(logitmodel4,newdata=testData,type="response")
pred.log4 <- ifelse(round(pred_prob4)==1,"Yes","No")
pred.log4 = as.factor(pred.log4)
pred4 <- ifelse(round(pred_prob4)==1,"Yes","No")
accuracy_table_log4 <- table(pred4, testData[,"default"]) #create the prediction result table
accuracy.log4 <- sum(diag(accuracy_table_log4))/sum(accuracy_table_log4)
accuracy_list_log.4[i] <- accuracy.log4
####student
logitmodel5 <- glm(default ~ income+balance+student, family=binomial(link='logit'),data=trainData)
pred_prob5 <- predict(logitmodel5,newdata=testData,type="response")
pred.log5 <- ifelse(round(pred_prob5)==1,"Yes","No")
pred.log5 = as.factor(pred.log5)
pred5 <- ifelse(round(pred_prob5)==1,"Yes","No")
accuracy_table_log5 <- table(pred5, testData[,"default"]) #create the prediction result table
accuracy.log5 <- sum(diag(accuracy_table_log5))/sum(accuracy_table_log5)
accuracy_list_log.5[i] <- accuracy.log5
####balance + student
logitmodel6 <- glm(default ~ balance+student, family=binomial(link='logit'),data=trainData)
pred_prob6 <- predict(logitmodel6,newdata=testData,type="response")
pred.log6 <- ifelse(round(pred_prob6)==1,"Yes","No")
pred.log6 = as.factor(pred.log6)
pred6 <- ifelse(round(pred_prob6)==1,"Yes","No")
accuracy_table_log6 <- table(pred6, testData[,"default"]) #create the prediction result table
accuracy.log6 <- sum(diag(accuracy_table_log6))/sum(accuracy_table_log6)
accuracy_list_log.6[i] <- accuracy.log6
####income + student
logitmodel7 <- glm(default ~ income+student, family=binomial(link='logit'),data=trainData)
pred_prob7 <- predict(logitmodel7,newdata=testData,type="response")
pred.log7 <- ifelse(round(pred_prob7)==1,"Yes","No")
pred.log7 = as.factor(pred.log7)
pred7 <- ifelse(round(pred_prob7)==1,"Yes","No")
accuracy_table_log7 <- table(pred7, testData[,"default"]) #create the prediction result table
accuracy.log7 <- sum(diag(accuracy_table_log7))/sum(accuracy_table_log7)
accuracy_list_log.7[i] <- accuracy.log7
#save data for #2
if (i == 2) {
pred.nb.2 = pred.nb.4
pred.log.2 = pred.log4
test2 = testData
}
}
cat("logistic model (income) accuracy and mean")
accuracy_list_log.1
mean(accuracy_list_log.1)
cat("logistic model (balance) accuracy and mean")
accuracy_list_log.2
mean(accuracy_list_log.2)
cat("logistic model (student) accuracy and mean")
accuracy_list_log.3
mean(accuracy_list_log.3)
cat("logistic model (income+balance) accuracy and mean")
accuracy_list_log.4
mean(accuracy_list_log.4)
cat("logistic model (income+student) accuracy and mean")
accuracy_list_log.7
mean(accuracy_list_log.7)
cat("logistic model (balance+student) accuracy and mean")
accuracy_list_log.6
mean(accuracy_list_log.6)
cat("logistic model (income+balance+student) accuracy and mean")
accuracy_list_log.5
mean(accuracy_list_log.5)
cat("naive bayes model (income) accuracy and mean")
accuracy_list_log.1
mean(accuracy_list_nb.1)
cat("naive bayes (balance) accuracy and mean")
accuracy_list_log.2
mean(accuracy_list_nb.2)
cat("naive bayes (student) accuracy and mean")
accuracy_list_log.3
mean(accuracy_list_nb.3)
cat("naive bayes (income+balance) accuracy and mean")
accuracy_list_log.4
mean(accuracy_list_nb.4)
cat("naive bayes (income+balance+student) accuracy and mean")
accuracy_list_log.7
mean(accuracy_list_nb.7)
cat("naive bayes (income+balance+student) accuracy and mean")
accuracy_list_log.6
mean(accuracy_list_nb.6)
cat("naive bayes (income+balance+student) accuracy and mean")
accuracy_list_log.5
mean(accuracy_list_nb.5)
# Naive Bayesâ€™ Classifier
library(e1071)
if(!require("caret")) install.packages("caret")
library("caret")
yourData<-Default[sample(nrow(Default)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(yourData)),breaks=10,labels=FALSE)
#Perform 10-fold cross validation
accuracy_list_log.1 <- NULL
accuracy_list_log.2 <- NULL
accuracy_list_log.3 <- NULL
accuracy_list_log.4 <- NULL
accuracy_list_log.5 <- NULL
accuracy_list_log.6 <- NULL
accuracy_list_log.7 <- NULL
accuracy_list_nb.1 <- NULL
accuracy_list_nb.2 <- NULL
accuracy_list_nb.3 <- NULL
accuracy_list_nb.4 <- NULL
accuracy_list_nb.5 <- NULL
accuracy_list_nb.6 <- NULL
accuracy_list_nb.7 <- NULL
for(i in 1:10){
#Segement data by fold using the which() function
testIndexes <- which(folds==i,arr.ind=TRUE)
testData <- yourData[testIndexes, ]
trainData <- yourData[-testIndexes, ]
#create model/prediction/accuracy using income
naiveBayesmodel1 <- naiveBayes(default ~ income, data = trainData) # consider two predictors
pred.nb.1 <- predict(naiveBayesmodel1,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_1 <- table(pred.nb.1, testData[,"default"]) #create the prediction result table
accuracy.nb.1 <- sum(diag(accuracy_table_nb_1))/sum(accuracy_table_nb_1)
accuracy_list_nb.1[i] <- accuracy.nb.1
#create model/prediction/accuracy using balance
naiveBayesmodel2 <- naiveBayes(default ~ balance, data = trainData) # consider two predictors
pred.nb.2 <- predict(naiveBayesmodel2,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_2 <- table(pred.nb.2, testData[,"default"]) #create the prediction result table
accuracy.nb.2 <- sum(diag(accuracy_table_nb_2))/sum(accuracy_table_nb_2)
accuracy_list_nb.2[i] <- accuracy.nb.2
#create model/prediction/accuracy using student
naiveBayesmodel3 <- naiveBayes(default ~ student, data = trainData) # consider two predictors
pred.nb.3 <- predict(naiveBayesmodel3,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_3 <- table(pred.nb.3, testData[,"default"]) #create the prediction result table
accuracy.nb.3 <- sum(diag(accuracy_table_nb_3))/sum(accuracy_table_nb_3)
accuracy_list_nb.3[i] <- accuracy.nb.3
#create model/prediction/accuracy using income+balance
naiveBayesmodel4 <- naiveBayes(default ~ income+balance, data = trainData) # consider two predictors
pred.nb.4 <- predict(naiveBayesmodel4,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_4 <- table(pred.nb.4, testData[,"default"]) #create the prediction result table
accuracy.nb.4 <- sum(diag(accuracy_table_nb_4))/sum(accuracy_table_nb_4)
accuracy_list_nb.4[i] <- accuracy.nb.4
#create model/prediction/accuracy using income+balance+student
naiveBayesmodel5 <- naiveBayes(default ~ income+balance+student, data = trainData) # consider two predictors
pred.nb.5 <- predict(naiveBayesmodel5,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_5 <- table(pred.nb.5, testData[,"default"]) #create the prediction result table
accuracy.nb.5 <- sum(diag(accuracy_table_nb_5))/sum(accuracy_table_nb_5)
accuracy_list_nb.5[i] <- accuracy.nb.5
#create model/prediction/accuracy using balance+student
naiveBayesmodel6 <- naiveBayes(default ~ balance+student, data = trainData) # consider two predictors
pred.nb.6 <- predict(naiveBayesmodel6,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_6 <- table(pred.nb.6, testData[,"default"]) #create the prediction result table
accuracy.nb.6 <- sum(diag(accuracy_table_nb_6))/sum(accuracy_table_nb_6)
accuracy_list_nb.6[i] <- accuracy.nb.6
#create model/prediction/accuracy using income+student
naiveBayesmodel7 <- naiveBayes(default ~ income+student, data = trainData) # consider two predictors
pred.nb.7 <- predict(naiveBayesmodel7,testData) #predic the class label of default behavior with different balance values in the testing data
accuracy_table_nb_7 <- table(pred.nb.7, testData[,"default"]) #create the prediction result table
accuracy.nb.7 <- sum(diag(accuracy_table_nb_7))/sum(accuracy_table_nb_7)
accuracy_list_nb.7[i] <- accuracy.nb.7
# cat("logistic regression model for ith fold: ", i, "\n")
# Run the logistic regression model  for categorical label prediction
logitmodel1 <- glm(default ~ income, family=binomial(link='logit'),data=trainData)
pred_prob1 <- predict(logitmodel1,newdata=testData,type="response")
pred.log1 <- ifelse(round(pred_prob1)==1,"Yes","No")
pred.log1= as.factor(pred.log1)
pred1 <- ifelse(round(pred_prob1)==1,"Yes","No") #ed1, testData[,"default"]) #create the prediction result table
accuracy_table_log1 <- table(pred1, testData[,"default"]) #create the prediction result table
accuracy.log1 <- sum(diag(accuracy_table_log1))/sum(accuracy_table_log1)
accuracy_list_log.1[i] <- accuracy.log1
####balance
logitmodel2 <- glm(default ~ balance, family=binomial(link='logit'),data=trainData)
pred_prob2 <- predict(logitmodel2,newdata=testData,type="response") #predic the probablity of default behavior with different balance values
pred.log2 <- ifelse(round(pred_prob2)==1,"Yes","No")
pred.log2= as.factor(pred.log2)
pred2 <- ifelse(round(pred_prob2)==1,"Yes","No")
accuracy_table_log2 <- table(pred2, testData[,"default"]) #create the prediction result table
accuracy.log2 <- sum(diag(accuracy_table_log2))/sum(accuracy_table_log2)
accuracy_list_log.2[i] <- accuracy.log2
####student
logitmodel3 <- glm(default ~ student, family=binomial(link='logit'),data=trainData)
pred_prob3 <- predict(logitmodel3,newdata=testData,type="response")
pred.log3 <- ifelse(round(pred_prob3)==1,"Yes","No")
pred.log3= as.factor(pred.log3)
pred3 <- ifelse(round(pred_prob3)==1,"Yes","No")
accuracy_table_log3 <- table(pred3, testData[,"default"]) #create the prediction result table
accuracy.log3 <- sum(diag(accuracy_table_log3))/sum(accuracy_table_log3)
accuracy_list_log.3[i] <- accuracy.log3
####income+balance
logitmodel4 <- glm(default ~ income+balance, family=binomial(link='logit'),data=trainData)
pred_prob4 <- predict(logitmodel4,newdata=testData,type="response")
pred.log4 <- ifelse(round(pred_prob4)==1,"Yes","No")
pred.log4 = as.factor(pred.log4)
pred4 <- ifelse(round(pred_prob4)==1,"Yes","No")
accuracy_table_log4 <- table(pred4, testData[,"default"]) #create the prediction result table
accuracy.log4 <- sum(diag(accuracy_table_log4))/sum(accuracy_table_log4)
accuracy_list_log.4[i] <- accuracy.log4
####student
logitmodel5 <- glm(default ~ income+balance+student, family=binomial(link='logit'),data=trainData)
pred_prob5 <- predict(logitmodel5,newdata=testData,type="response")
pred.log5 <- ifelse(round(pred_prob5)==1,"Yes","No")
pred.log5 = as.factor(pred.log5)
pred5 <- ifelse(round(pred_prob5)==1,"Yes","No")
accuracy_table_log5 <- table(pred5, testData[,"default"]) #create the prediction result table
accuracy.log5 <- sum(diag(accuracy_table_log5))/sum(accuracy_table_log5)
accuracy_list_log.5[i] <- accuracy.log5
####balance + student
logitmodel6 <- glm(default ~ balance+student, family=binomial(link='logit'),data=trainData)
pred_prob6 <- predict(logitmodel6,newdata=testData,type="response")
pred.log6 <- ifelse(round(pred_prob6)==1,"Yes","No")
pred.log6 = as.factor(pred.log6)
pred6 <- ifelse(round(pred_prob6)==1,"Yes","No")
accuracy_table_log6 <- table(pred6, testData[,"default"]) #create the prediction result table
accuracy.log6 <- sum(diag(accuracy_table_log6))/sum(accuracy_table_log6)
accuracy_list_log.6[i] <- accuracy.log6
####income + student
logitmodel7 <- glm(default ~ income+student, family=binomial(link='logit'),data=trainData)
pred_prob7 <- predict(logitmodel7,newdata=testData,type="response")
pred.log7 <- ifelse(round(pred_prob7)==1,"Yes","No")
pred.log7 = as.factor(pred.log7)
pred7 <- ifelse(round(pred_prob7)==1,"Yes","No")
accuracy_table_log7 <- table(pred7, testData[,"default"]) #create the prediction result table
accuracy.log7 <- sum(diag(accuracy_table_log7))/sum(accuracy_table_log7)
accuracy_list_log.7[i] <- accuracy.log7
#save data for #2
if (i == 2) {
pred.nb.2 = pred.nb.4
pred.log.2 = pred.log4
test2 = testData
}
}
cat("logistic model (income) accuracy and mean")
accuracy_list_log.1
mean(accuracy_list_log.1)
cat("logistic model (balance) accuracy and mean")
accuracy_list_log.2
mean(accuracy_list_log.2)
cat("logistic model (student) accuracy and mean")
accuracy_list_log.3
mean(accuracy_list_log.3)
cat("logistic model (income+balance) accuracy and mean")
accuracy_list_log.4
mean(accuracy_list_log.4)
cat("logistic model (income+student) accuracy and mean")
accuracy_list_log.7
mean(accuracy_list_log.7)
cat("logistic model (balance+student) accuracy and mean")
accuracy_list_log.6
mean(accuracy_list_log.6)
cat("logistic model (income+balance+student) accuracy and mean")
accuracy_list_log.5
mean(accuracy_list_log.5)
cat("naive bayes model (income) accuracy and mean")
accuracy_list_log.1
mean(accuracy_list_nb.1)
cat("naive bayes (balance) accuracy and mean")
accuracy_list_log.2
mean(accuracy_list_nb.2)
cat("naive bayes (student) accuracy and mean")
accuracy_list_log.3
mean(accuracy_list_nb.3)
cat("naive bayes (income+balance) accuracy and mean")
accuracy_list_log.4
mean(accuracy_list_nb.4)
cat("naive bayes (income+balance+student) accuracy and mean")
accuracy_list_log.7
mean(accuracy_list_nb.7)
cat("naive bayes (income+balance+student) accuracy and mean")
accuracy_list_log.6
mean(accuracy_list_nb.6)
cat("naive bayes (income+balance+student) accuracy and mean")
accuracy_list_log.5
mean(accuracy_list_nb.5)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
avocado = read_csv("avocado-prices.csv")
setwd("~/Documents/geog575/d3-coordinated-viz/data")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
avocado = read_csv("avocado-prices.csv")
View(avocado)
avocado = read_csv("avocado-prices.csv")
plot(avocado)
View(avocado)
avocado = read_csv("avocado-prices.csv")
plot(State,Total_Volume)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(purrr)
library(tibble)
library(stringr)
library(forcats)
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Total_volume)) +
geom_point() +
# coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Total_Volume)) +
geom_point() +
# coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Total_Volume)) +
geom_point() +
coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Average_Price)) +
geom_point() +
coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Small_Hass)) +
geom_point() +
coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Total_Bags)) +
geom_point() +
coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
avocado = read_csv("avocado-prices.csv")
ggplot(avocado, aes(x=State, y=Average_Price)) +
geom_point() +
coord_flip() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
xlab("State") +
ylab("") +
theme_bw()
